{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "75de5d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import json\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e09b457e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file):\n",
    "    df = pd.read_csv(os.path.join(\"data\", file))\n",
    "    return df\n",
    "\n",
    "df = load_data(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "98120c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = load_data(\"test_data.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e11fc95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(df):\n",
    "\n",
    "\n",
    "    df = df.drop(df[df['station'].isin([\"leicestershire\",'humberside', 'lancashire','metropolitan','west-midlands'])].index)\n",
    "    \n",
    "    df['Part of a policing operation'] = df['Part of a policing operation'].fillna(False)\n",
    "    df['Part of a policing operation'] = df['Part of a policing operation'].astype(bool)\n",
    "\n",
    "    df['Outcome linked to object of search'] = df['Outcome linked to object of search'].fillna(False)\n",
    "\n",
    "    df['Legislation'] = df['Legislation'].fillna('unknown')\n",
    "    \n",
    "    df.loc[df['Outcome'] == 'A no further action disposal', 'Outcome linked to object of search'] = False\n",
    "    \n",
    "    success_outcomes = ['Community resolution', 'Khat or Cannabis warning', 'Caution (simple or conditional)', \n",
    "                    'Arrest', 'Penalty Notice for Disorder', 'Summons / charged by post', \n",
    "                    'Suspect arrested', 'Suspect summoned to court']\n",
    "\n",
    "    # create a new column called \"success\" with 1 if the outcome is in the list of successful outcomes, 0 otherwise\n",
    "    df['success'] = df.apply(lambda x: True if x['Outcome'] in success_outcomes and x['Outcome linked to object of search'] == True else False, axis=1)\n",
    "\n",
    "\n",
    "    #df=df.dropna()\n",
    "    return df\n",
    "\n",
    "df_new = clean(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e770c21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DateTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        X['Date'] = pd.to_datetime(X['Date'])\n",
    "        X['Hour'] = X['Date'].dt.hour\n",
    "        X['Month'] = X['Date'].dt.month\n",
    "        X['Day'] = X['Date'].dt.day\n",
    "        X['DayOfWeek'] = X['Date'].dt.weekday\n",
    "        X=X.drop(columns = \"Date\", axis=1)\n",
    "        \n",
    "        return X[['Hour','Month', 'Day', 'DayOfWeek']]\n",
    "\n",
    "    def get_feature_names_out(self):\n",
    "        return [('Date', 'Hour'), ('Date', 'Month'), ('Date', 'Day'),('Date', 'DayOfWeek')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dd322039",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;date_transformer&#x27;,\n",
       "                                                  DateTransformer(), [&#x27;Date&#x27;]),\n",
       "                                                 (&#x27;categorical_transformers&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                                   SimpleImputer(fill_value=&#x27;missing&#x27;,\n",
       "                                                                                 strategy=&#x27;constant&#x27;)),\n",
       "                                                                  (&#x27;onehot&#x27;,\n",
       "                                                                   OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n",
       "                                                  [&#x27;Legislation&#x27;,\n",
       "                                                   &#x27;Object of search&#x27;,\n",
       "                                                   &#x27;Part of a policing &#x27;\n",
       "                                                   &#x27;operation&#x27;,\n",
       "                                                   &#x27;Date&#x27;, &#x27;Age range&#x27;,\n",
       "                                                   &#x27;Gender&#x27;, &#x27;station&#x27;])])),\n",
       "                (&#x27;classifer&#x27;,\n",
       "                 LogisticRegression(C=1, class_weight=&#x27;balanced&#x27;, n_jobs=-1,\n",
       "                                    random_state=42))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;date_transformer&#x27;,\n",
       "                                                  DateTransformer(), [&#x27;Date&#x27;]),\n",
       "                                                 (&#x27;categorical_transformers&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                                   SimpleImputer(fill_value=&#x27;missing&#x27;,\n",
       "                                                                                 strategy=&#x27;constant&#x27;)),\n",
       "                                                                  (&#x27;onehot&#x27;,\n",
       "                                                                   OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n",
       "                                                  [&#x27;Legislation&#x27;,\n",
       "                                                   &#x27;Object of search&#x27;,\n",
       "                                                   &#x27;Part of a policing &#x27;\n",
       "                                                   &#x27;operation&#x27;,\n",
       "                                                   &#x27;Date&#x27;, &#x27;Age range&#x27;,\n",
       "                                                   &#x27;Gender&#x27;, &#x27;station&#x27;])])),\n",
       "                (&#x27;classifer&#x27;,\n",
       "                 LogisticRegression(C=1, class_weight=&#x27;balanced&#x27;, n_jobs=-1,\n",
       "                                    random_state=42))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocessor: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;date_transformer&#x27;, DateTransformer(),\n",
       "                                 [&#x27;Date&#x27;]),\n",
       "                                (&#x27;categorical_transformers&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                  SimpleImputer(fill_value=&#x27;missing&#x27;,\n",
       "                                                                strategy=&#x27;constant&#x27;)),\n",
       "                                                 (&#x27;onehot&#x27;,\n",
       "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n",
       "                                 [&#x27;Legislation&#x27;, &#x27;Object of search&#x27;,\n",
       "                                  &#x27;Part of a policing operation&#x27;, &#x27;Date&#x27;,\n",
       "                                  &#x27;Age range&#x27;, &#x27;Gender&#x27;, &#x27;station&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">date_transformer</label><div class=\"sk-toggleable__content\"><pre>[&#x27;Date&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DateTransformer</label><div class=\"sk-toggleable__content\"><pre>DateTransformer()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">categorical_transformers</label><div class=\"sk-toggleable__content\"><pre>[&#x27;Legislation&#x27;, &#x27;Object of search&#x27;, &#x27;Part of a policing operation&#x27;, &#x27;Date&#x27;, &#x27;Age range&#x27;, &#x27;Gender&#x27;, &#x27;station&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(fill_value=&#x27;missing&#x27;, strategy=&#x27;constant&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;)</pre></div></div></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=1, class_weight=&#x27;balanced&#x27;, n_jobs=-1, random_state=42)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('date_transformer',\n",
       "                                                  DateTransformer(), ['Date']),\n",
       "                                                 ('categorical_transformers',\n",
       "                                                  Pipeline(steps=[('imputer',\n",
       "                                                                   SimpleImputer(fill_value='missing',\n",
       "                                                                                 strategy='constant')),\n",
       "                                                                  ('onehot',\n",
       "                                                                   OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                                  ['Legislation',\n",
       "                                                   'Object of search',\n",
       "                                                   'Part of a policing '\n",
       "                                                   'operation',\n",
       "                                                   'Date', 'Age range',\n",
       "                                                   'Gender', 'station'])])),\n",
       "                ('classifer',\n",
       "                 LogisticRegression(C=1, class_weight='balanced', n_jobs=-1,\n",
       "                                    random_state=42))])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "features = [\"observation_id\",'Type','Part of a policing operation', 'Latitude', 'Longitude','Legislation', 'Object of search','Date',\"Age range\",\"Gender\",'station','Officer-defined ethnicity']\n",
    "target = 'success'\n",
    "\n",
    "X_train = df_new[features]\n",
    "y_train =  df_new[target]\n",
    "\n",
    "\n",
    "\n",
    "categorical_columns = ['Legislation', 'Object of search','Part of a policing operation','Date',\"Age range\",\"Gender\",'station']\n",
    "feat_columns = ['Date']\n",
    "\n",
    "categorical_transformer = Pipeline(\n",
    "    steps=[\n",
    "        ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore')),\n",
    "    ])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "       ('date_transformer', DateTransformer(), feat_columns),\n",
    "        ('categorical_transformers', categorical_transformer, categorical_columns),\n",
    "    ])\n",
    "\n",
    "\n",
    "preprocessor.fit(X_train)\n",
    "\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                           (\"classifer\",LogisticRegression(C=1, class_weight='balanced', n_jobs=-1, random_state=42))\n",
    "                           #(\"classifer\",GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3,random_state=42))\n",
    "                           #(\"Classifier\", LogisticRegression(n_jobs=-1))\n",
    "                           #(\"classifier\", RandomForestClassifier(n_estimators=100, max_depth=10, min_samples_leaf=5, class_weight=\"balanced\", random_state=42, n_jobs=-1))\n",
    "                            #(\"classifier\", LGBMClassifier(n_estimators=100, max_depth = 7,learning_rate=0.1,class_weight=\"balanced\", random_state=42, n_jobs=-1))\n",
    "                           \n",
    "                           \n",
    "                \n",
    "                            ])\n",
    "\n",
    "# Fit model on training data\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "606fa3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = df_train[features]\n",
    "y_test = df_train['Outcome']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b9dab8e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ew\n",
      "LogisticRegression(C=1, class_weight='balanced', n_jobs=-1, random_state=42)\n",
      "threshold 0.33\n",
      "F1 score: 0.37464104263309034\n",
      "Recall score: 0.9592760180995475\n",
      "Precision score: 0.23277518528685148\n",
      "ROC score: 0.5340066314987534\n",
      "\n",
      "\n",
      "Gender\n",
      "Requirement failed 😢\n",
      "Num problematic departments: 3\n",
      "Num good departments: 3\n",
      "avg diff: 0.10442316965681592\n",
      "\n",
      "Ethnicity\n",
      "Requirement failed 😢\n",
      "Num problematic departments: 6\n",
      "Num good departments: 0\n",
      "avg diff: 0.23957401520848187\n",
      "\n",
      " age \n",
      "Requirement failed 😢\n",
      "Num problematic departments: 6\n",
      "Num good departments: 0\n",
      "avg diff: 0.1919675841812527\n",
      "\n",
      "\n",
      "[[0.10873724 0.89126276]\n",
      " [0.04072398 0.95927602]]\n",
      "0.17865492301551686\n",
      "Departments analysed: 6\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "ew\n",
      "LGBMClassifier(class_weight='balanced', max_depth=3, random_state=42)\n",
      "threshold 0.36\n",
      "F1 score: 0.3752503894947697\n",
      "Recall score: 0.9536199095022625\n",
      "Precision score: 0.23358270989193683\n",
      "ROC score: 0.5358023016899067\n",
      "\n",
      "\n",
      "Gender\n",
      "Requirement failed 😢\n",
      "Num problematic departments: 2\n",
      "Num good departments: 4\n",
      "avg diff: 0.12458377109539902\n",
      "\n",
      "Ethnicity\n",
      "Requirement failed 😢\n",
      "Num problematic departments: 6\n",
      "Num good departments: 0\n",
      "avg diff: 0.2340949316296791\n",
      "\n",
      " age \n",
      "Requirement failed 😢\n",
      "Num problematic departments: 6\n",
      "Num good departments: 0\n",
      "avg diff: 0.20033799330711174\n",
      "\n",
      "\n",
      "[[0.11798469 0.88201531]\n",
      " [0.04638009 0.95361991]]\n",
      "0.1863388986773966\n",
      "Departments analysed: 6\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/francisco/.virtualenvs/ldsa/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/francisco/.virtualenvs/ldsa/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/francisco/.virtualenvs/ldsa/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/francisco/.virtualenvs/ldsa/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def verify_no_discrimination(X_test, y_true, y_pred, sensitive_column='Age range', max_diff=0.05):\n",
    "    \"\"\"\n",
    "    Verifies that no department has discrimination in between protected age ranges\n",
    "    \"\"\"\n",
    "    \n",
    "    departments = X_test['station'].unique()\n",
    "    sensitive_classes = X_test[sensitive_column].unique()\n",
    "    \n",
    "    is_satisfied = True\n",
    "    problematic_departments = []\n",
    "    good_departments = []\n",
    "    for department in departments:\n",
    "        precisions = {}\n",
    "        for sensitive_class in sensitive_classes:\n",
    "            mask = (X_test[sensitive_column] == sensitive_class) & (X_test['station'] == department)\n",
    "            if mask.sum():\n",
    "                precisions[sensitive_class] = precision_score(y_true[mask], y_pred[mask], pos_label=1, zero_division=0)\n",
    "                \n",
    "        diff = np.max(list(precisions.values())) - np.min(list(precisions.values()))\n",
    "        if diff > max_diff:\n",
    "            is_satisfied = False\n",
    "            problematic_departments.append((department, diff, precisions))\n",
    "        else:\n",
    "            good_departments.append((department, diff, precisions))\n",
    "\n",
    "    return is_satisfied, problematic_departments, good_departments\n",
    "\n",
    "classifiers = [\n",
    "    LogisticRegression(C=1, class_weight='balanced', n_jobs=-1, random_state=42),\n",
    "    LGBMClassifier(n_estimators=100, max_depth = 3,learning_rate=0.1,class_weight=\"balanced\", random_state=42, n_jobs=-1)\n",
    "\n",
    "]\n",
    "\n",
    "i=0\n",
    "for classifier in classifiers:\n",
    "    print(\"\\n\\new\")\n",
    "    print(classifier)\n",
    "    pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                               ('classifier', classifier)])\n",
    "\n",
    "    # Fit model on training data\n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "    y_pred_proba = pipeline.predict_proba(X_test)[:, 1] # Get predicted probabilities for positive class\n",
    "    \n",
    "\n",
    "    l =[0.95]\n",
    "    \n",
    "    for s in l:\n",
    "    \n",
    "    \n",
    "        best_threshold = 0\n",
    "        best_false_false_rate = 0\n",
    "        recall_range = (s, 1)\n",
    "\n",
    "        for threshold in range(0, 100):\n",
    "            threshold /= 100\n",
    "            y_pred = (y_pred_proba > threshold).astype(int)\n",
    "            tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "            false_false_rate = tn / (tn + fp)\n",
    "            recall = tp / (tp + fn)\n",
    "            if false_false_rate > best_false_false_rate and recall_range[0] <= recall <= recall_range[1]:\n",
    "                best_threshold = threshold\n",
    "                best_false_false_rate = false_false_rate\n",
    "\n",
    "        threshold = best_threshold \n",
    "        #threshold =0.38\n",
    "        #thresholds = [0.35,0.38]\n",
    "        \n",
    "        #threshold=thresholds[i]\n",
    "        #i+=1\n",
    "        \n",
    "        print(\"threshold\",threshold)\n",
    "        y_pred = (y_pred_proba > threshold).astype(int)\n",
    "\n",
    "\n",
    "        print('F1 score:', f1_score(y_test, y_pred))\n",
    "        print('Recall score:', recall_score(y_test, y_pred))\n",
    "        print('Precision score:', precision_score(y_test, y_pred))\n",
    "        print(\"ROC score:\", roc_auc_score(y_test, y_pred))\n",
    "\n",
    "        print(\"\\n\\nGender\")\n",
    "        is_satisfied, problematic_departments, good_deparments = verify_no_discrimination(\n",
    "            X_test, y_test, y_pred, sensitive_column='Gender')\n",
    "\n",
    "        if not is_satisfied:\n",
    "            print(\"Requirement failed 😢\")\n",
    "            print(\"Num problematic departments: {}\".format(len(problematic_departments)))\n",
    "            print(\"Num good departments: {}\".format(len(good_deparments)))\n",
    "            g_a= np.mean([p[1] for p in problematic_departments])\n",
    "            print(\"avg diff:\", np.mean([p[1] for p in problematic_departments]))\n",
    "\n",
    "\n",
    "        print(\"\\nEthnicity\")\n",
    "        is_satisfied, problematic_departments, good_deparments = verify_no_discrimination(\n",
    "            X_test, y_test, y_pred, sensitive_column='Officer-defined ethnicity')\n",
    "\n",
    "        if not is_satisfied:\n",
    "            print(\"Requirement failed 😢\")\n",
    "            print(\"Num problematic departments: {}\".format(len(problematic_departments)))\n",
    "            print(\"Num good departments: {}\".format(len(good_deparments)))\n",
    "            e_a = np.mean([p[1] for p in problematic_departments])\n",
    "            print(\"avg diff:\", np.mean([p[1] for p in problematic_departments]))\n",
    "        else:\n",
    "            print(\"Requirement satisfied! 🚀\")\n",
    "\n",
    "\n",
    "        print(\"\\n age \")\n",
    "        is_satisfied, problematic_departments, good_deparments = verify_no_discrimination(\n",
    "            X_test, y_test, y_pred)\n",
    "\n",
    "        if not is_satisfied:\n",
    "            print(\"Requirement failed 😢\")\n",
    "            print(\"Num problematic departments: {}\".format(len(problematic_departments)))\n",
    "            print(\"Num good departments: {}\".format(len(good_deparments)))\n",
    "            a_a = np.mean([p[1] for p in problematic_departments])\n",
    "            print(\"avg diff:\", np.mean([p[1] for p in problematic_departments]))\n",
    "        else:\n",
    "            print(\"Requirement satisfied! 🚀\")\n",
    "\n",
    "        cm = confusion_matrix(y_test, y_pred, labels=pipeline.classes_, normalize='true')\n",
    "        print(\"\\n\")\n",
    "        print(cm)\n",
    "        print((a_a+g_a+e_a)/3)\n",
    "\n",
    "        print(\"Departments analysed: {}\".format(len(problematic_departments) + len(good_deparments)))\n",
    "        print('--------------------------------------------------------------------------------')\n",
    "    print('--------------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179ce86b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
